{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q tqdm\n",
    "!pip install -q tensorboard\n",
    "!pip install -q segmentation-models-pytorch\n",
    "!pip install -q torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "import collections\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import torchvision.transforms.functional as F  # TODO Fにするのは, transforms.functionalなのか、nn.functionalなのか、両方しないのか\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchinfo import summary\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import draw_segmentation_masks\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logging Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:27:06.782978Z",
     "iopub.status.busy": "2023-02-14T08:27:06.782573Z",
     "iopub.status.idle": "2023-02-14T08:27:06.811153Z",
     "shell.execute_reply": "2023-02-14T08:27:06.810112Z",
     "shell.execute_reply.started": "2023-02-14T08:27:06.782902Z"
    }
   },
   "outputs": [],
   "source": [
    "root_logger = logging.getLogger(__name__)\n",
    "root_logger.setLevel(logging.INFO)\n",
    "\n",
    "for handler in list(root_logger.handlers):\n",
    "    root_logger.removeHandler(handler)\n",
    "\n",
    "logfmt_str = \"%(asctime)s %(levelname)-8s pid:%(process)d %(name)s:%(lineno)03d:%(funcName)s %(message)s\"\n",
    "formatter = logging.Formatter(logfmt_str)\n",
    "\n",
    "streameHandler = logging.StreamHandler()\n",
    "streameHandler.setFormatter(formatter)\n",
    "streameHandler.setLevel(logging.DEBUG)\n",
    "\n",
    "root_logger.addHandler(streameHandler)\n",
    "\n",
    "log = logging.getLogger(__name__)\n",
    "log.setLevel(logging.INFO)\n",
    "log.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:27:09.302572Z",
     "iopub.status.busy": "2023-02-14T08:27:09.302112Z",
     "iopub.status.idle": "2023-02-14T08:27:22.977453Z",
     "shell.execute_reply": "2023-02-14T08:27:22.976218Z",
     "shell.execute_reply.started": "2023-02-14T08:27:09.302531Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda; 1 devices.\n"
     ]
    }
   ],
   "source": [
    "# Deviceの設定\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEBUG_MODE = None\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Using {device}; {torch.cuda.device_count()} devices.\")\n",
    "else:\n",
    "    DEBUG_MODE = True\n",
    "    print(f\"Using {device}\")\n",
    "\n",
    "# Modelの設定\n",
    "\n",
    "# MODEL_STR は以下から選ぶ\n",
    "# \"debug\", \"Init\", \"UNet\", \"UNet_Pad\", \"UNet_BN\", \"UNet_with_library\", \"MANet\"\n",
    "MODEL_STR = \"MANet\"\n",
    "if DEBUG_MODE:\n",
    "    MODEL_STR = \"debug\"\n",
    "\n",
    "RESIZE = True\n",
    "\n",
    "EPOCHS = 30\n",
    "BATCH_SIZE = 8\n",
    "NUM_WORKERS = 1\n",
    "\n",
    "# CUDAのメモリの割当の設定\n",
    "# !env PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:36:11.203619Z",
     "iopub.status.busy": "2023-02-14T08:36:11.203223Z",
     "iopub.status.idle": "2023-02-14T08:36:21.563697Z",
     "shell.execute_reply": "2023-02-14T08:36:21.562661Z",
     "shell.execute_reply.started": "2023-02-14T08:36:11.203584Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def init_tensor_board_writers(train_writer=None):\n",
    "    if train_writer is None:\n",
    "        model_name = type(model).__name__\n",
    "        base_dir = os.path.dirname(os.path.abspath('.'))\n",
    "        time_str = datetime.datetime.now().strftime('%Y_%m_%d_%H.%M.%S')\n",
    "        log_dir = os.path.join(base_dir, 'working', 'log', '{model}_{epochs}epochs_{batch_size}batches'.format(model=model_name, epochs=EPOCHS, batch_size=BATCH_SIZE), time_str)\n",
    "        train_writer = SummaryWriter(log_dir=log_dir + '_train_seg_')\n",
    "        val_writer = SummaryWriter(log_dir=log_dir + '_val_seg_')\n",
    "        return train_writer, val_writer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# データの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:27:52.469056Z",
     "iopub.status.busy": "2023-02-14T08:27:52.468699Z",
     "iopub.status.idle": "2023-02-14T08:27:52.476964Z",
     "shell.execute_reply": "2023-02-14T08:27:52.475987Z",
     "shell.execute_reply.started": "2023-02-14T08:27:52.469026Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_subject_image_idx(path: str) -> tuple:\n",
    "    filename = os.path.splitext(os.path.basename(path))[0]\n",
    "    subject, image_idx = map(int, filename.split('_')[:2])\n",
    "    return subject, image_idx\n",
    "\n",
    "\n",
    "def get_data_path():\n",
    "    train_dir = '../input/ultrasound-nerve-segmentation/train'\n",
    "    input_img_paths = []\n",
    "    target_paths = []\n",
    "\n",
    "    for filename in os.listdir(train_dir):\n",
    "        if filename.endswith(\"mask.tif\"):\n",
    "            target_paths.append(os.path.join(train_dir, filename))\n",
    "        elif filename.endswith(\".tif\"):\n",
    "            input_img_paths.append(os.path.join(train_dir, filename))\n",
    "\n",
    "    input_img_paths.sort(key=lambda x: get_subject_image_idx(x))\n",
    "    target_paths.sort(key=lambda x: get_subject_image_idx(x))\n",
    "    data_paths = [(input_img, target) for input_img, target in zip(input_img_paths, target_paths)]\n",
    "\n",
    "    return data_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの確認"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:34:21.948335Z",
     "iopub.status.busy": "2023-02-14T08:34:21.947883Z",
     "iopub.status.idle": "2023-02-14T08:34:22.120142Z",
     "shell.execute_reply": "2023-02-14T08:34:22.119229Z",
     "shell.execute_reply.started": "2023-02-14T08:34:21.948296Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 06:34:52,505 INFO     pid:17999 __main__:028:<cell line: 28> 5635 samples in total.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    subject  Image Num\n",
      "0         1        120\n",
      "1         2        120\n",
      "2         3        119\n",
      "3         4        120\n",
      "4         5        120\n",
      "5         6        120\n",
      "6         7        119\n",
      "7         8        120\n",
      "8         9        120\n",
      "9        10        120\n",
      "10       11        120\n",
      "11       12        120\n",
      "12       13        120\n",
      "13       14        120\n",
      "14       15        120\n",
      "15       16        120\n",
      "16       17        119\n",
      "17       18        120\n",
      "18       19        120\n",
      "19       20        120\n",
      "20       21        120\n",
      "21       22        120\n",
      "22       23        120\n",
      "23       24        120\n",
      "24       25        120\n",
      "25       26        120\n",
      "26       27        120\n",
      "27       28        120\n",
      "28       29        120\n",
      "29       30        120\n",
      "30       31        120\n",
      "31       32        120\n",
      "32       33        120\n",
      "33       34        119\n",
      "34       35        120\n",
      "35       36        120\n",
      "36       37        120\n",
      "37       38        120\n",
      "38       39        120\n",
      "39       40        120\n",
      "40       41        120\n",
      "41       42        120\n",
      "42       43        120\n",
      "43       44        119\n",
      "44       45        120\n",
      "45       46        120\n",
      "46       47        120\n"
     ]
    }
   ],
   "source": [
    "def count_num_imgs_for_subject():\n",
    "    data_paths = get_data_path()\n",
    "    subject_l = [get_subject_image_idx(input_img_path)[0] for input_img_path, target_path in data_paths]\n",
    "    sample_counter = collections.Counter(subject_l)\n",
    "    return sample_counter\n",
    "\n",
    "def show_sample_counter():\n",
    "    sample_counter = count_num_imgs_for_subject()\n",
    "    sample_counter = [{'subject': key, 'Image Num': value} for key, value in sample_counter.items()]\n",
    "    log.info(sample_counter)\n",
    "    \n",
    "def in_nerve(target_path):\n",
    "    target = Image.open(target_path)\n",
    "    return target.getextrema()[1] > 0\n",
    "\n",
    "show_sample_counter()\n",
    "\n",
    "num_data = len(get_data_path())\n",
    "log.info('{} samples in total.'.format(num_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasetの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:34:59.600765Z",
     "iopub.status.busy": "2023-02-14T08:34:59.599904Z",
     "iopub.status.idle": "2023-02-14T08:34:59.613171Z",
     "shell.execute_reply": "2023-02-14T08:34:59.612235Z",
     "shell.execute_reply.started": "2023-02-14T08:34:59.600731Z"
    }
   },
   "outputs": [],
   "source": [
    "class UltrasoundNerveDataset(Dataset):\n",
    "    \"\"\"Ultrasound image and Nerve structure dataset return the PIL image.\"\"\"\n",
    "\n",
    "    def __init__(self, is_val: bool=None, val_stride: int=0, only_nerve_imgs: bool=False, subject_img_idx: tuple=None, is_random: bool=None, transform=None, data_num: int=None):\n",
    "        self.data_paths = get_data_path()\n",
    "\n",
    "        if is_random:\n",
    "            random.Random(111).shuffle(self.data_paths)\n",
    "\n",
    "        if only_nerve_imgs:\n",
    "            self.data_paths = [(input_img, target) for input_img, target in self.data_paths if in_nerve(target)]\n",
    "\n",
    "        if subject_img_idx:\n",
    "            self.data_paths = [path_tuple for path_tuple in self.data_paths if get_subject_image_idx(path_tuple[0]) == subject_img_idx]\n",
    "\n",
    "        if data_num:\n",
    "            self.data_paths = self.data_paths[:data_num]\n",
    "\n",
    "\n",
    "        if is_val:\n",
    "            assert val_stride > 0, val_stride\n",
    "            self.data_paths = self.data_paths[::val_stride]\n",
    "            assert self.data_paths\n",
    "        elif val_stride > 0:\n",
    "            del self.data_paths[::val_stride]\n",
    "            assert self.data_paths\n",
    "\n",
    "        log.info(\"{!r}: {} {} samples\".format(self, len(self.data_paths), \"validation\" if is_val else \"training\"))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        input_img_path, target_path = self.data_paths[idx]\n",
    "        img = Image.open(input_img_path)\n",
    "        target = Image.open(target_path)\n",
    "\n",
    "        sample = {'img': img, 'target': target}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 前処理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### テンソル化する（imageとtargetで処理を変える）\n",
    "# - Image: Tensorにして、MaxMinScale\n",
    "# - Target: そのままTensorにする\n",
    "\n",
    "def select_transform(resize: bool):\n",
    "    if resize:\n",
    "        return transforms.Compose([\n",
    "            PILToTensor(),\n",
    "            Normalize(mean=[MEAN], std=[STD]),\n",
    "            Resize32Multiple(),\n",
    "                ])\n",
    "    return transforms.Compose([\n",
    "        PILToTensor(),\n",
    "        Normalize(mean=[MEAN], std=[STD]),\n",
    "        ])\n",
    "\n",
    "TRANSFORM = select_transform(RESIZE)\n",
    "\n",
    "\n",
    "class PILToTensor:\n",
    "    def __call__(self, sample):\n",
    "        img_pil, target = sample['img'], sample['target']\n",
    "        img = F.to_tensor(img_pil)\n",
    "        img_vis = F.pil_to_tensor(img_pil)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.float64)\n",
    "        target = torch.div(target, 255, rounding_mode='floor')\n",
    "        sample = {'img': img, 'target': target, 'img_vis': img_vis}\n",
    "        return sample\n",
    "\n",
    "### 正規化\n",
    "\n",
    "# メモリを使わないように、計算は繰り返さない\n",
    "\n",
    "# dataset_to_calculate_mean_std = UltrasoundNerveDataset(transform=PILToTensor())\n",
    "# imgs = [sample['img'] for sample in dataset_to_calculate_mean_std]\n",
    "# imgs_t = torch.stack(imgs, dim=3)\n",
    "# MEAN = imgs_t.view(1, -1).mean(dim=1)\n",
    "# STD = imgs_t.view(1, -1).std(dim=1)\n",
    "# log.info(f\"Mean: {MEAN}, Standard deviation: {STD}\")\n",
    "\n",
    "MEAN = 0.3898\n",
    "STD = 0.2219\n",
    "\n",
    "class Normalize:\n",
    "    def __init__(self, mean: list, std: list):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        img = sample['img']\n",
    "        img = F.normalize(img, self.mean, self.std)\n",
    "        sample['img'] = img\n",
    "        return sample\n",
    "\n",
    "### Resize\n",
    "\n",
    "class Resize32Multiple:\n",
    "    def __init__(self):\n",
    "        self.pad = nn.ConstantPad2d(14, 0)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        img, target, img_vis = sample['img'], sample['target'], sample['img_vis']\n",
    "        img = self.pad(img)\n",
    "        target = self.pad(target)\n",
    "        img_vis = self.pad(img_vis)\n",
    "        sample = {'img': img, 'target': target, 'img_vis': img_vis}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loaderの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:35:18.904037Z",
     "iopub.status.busy": "2023-02-14T08:35:18.903614Z",
     "iopub.status.idle": "2023-02-14T08:35:18.914100Z",
     "shell.execute_reply": "2023-02-14T08:35:18.912998Z",
     "shell.execute_reply.started": "2023-02-14T08:35:18.903997Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_dataloader(is_val: bool=None, only_nerve_imgs: bool=None, transform=TRANSFORM, data_num=None):\n",
    "    batch_size = BATCH_SIZE\n",
    "    num_workers = NUM_WORKERS\n",
    "    if torch.cuda.is_available():\n",
    "        batch_size *= torch.cuda.device_count()\n",
    "\n",
    "    dataset = UltrasoundNerveDataset(is_val=is_val, val_stride=3, is_random=True, only_nerve_imgs=only_nerve_imgs, transform=TRANSFORM, data_num=data_num)\n",
    "\n",
    "    data_loader = DataLoader(dataset=dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers, pin_memory=torch.cuda.is_available())\n",
    "\n",
    "    return data_loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 損失関数定義"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 指標を定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:35:14.865847Z",
     "iopub.status.busy": "2023-02-14T08:35:14.865456Z",
     "iopub.status.idle": "2023-02-14T08:35:14.871183Z",
     "shell.execute_reply": "2023-02-14T08:35:14.870065Z",
     "shell.execute_reply.started": "2023-02-14T08:35:14.865815Z"
    }
   },
   "outputs": [],
   "source": [
    "METRICS_DICE_LOSS_NDX = 0\n",
    "METRICS_DICE_COEFFICIENT_NDX = 1\n",
    "METRICS_TP_NDX = 2\n",
    "METRICS_FN_NDX = 3\n",
    "METRICS_FP_NDX = 4\n",
    "METRICS_SIZE = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数とバッチ損失"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:35:18.101572Z",
     "iopub.status.busy": "2023-02-14T08:35:18.101097Z",
     "iopub.status.idle": "2023-02-14T08:35:18.121334Z",
     "shell.execute_reply": "2023-02-14T08:35:18.120399Z",
     "shell.execute_reply.started": "2023-02-14T08:35:18.101530Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_dice_loss(prediction, target):\n",
    "    epsilon = 1\n",
    "\n",
    "    dice_prediction = prediction.sum(dim=[1, 2, 3])    # 要素iには、バッチiの、各ピクセルについて陽性である確率の総和\n",
    "    dice_label = target.sum(dim=[1, 2, 3])    # 要素iには、バッチiの陽性ラベルの数\n",
    "    dice_correct = (target * prediction).sum(dim=[1, 2, 3])\n",
    "\n",
    "    dice_ratio = (2 * dice_correct + epsilon) / (dice_prediction + dice_label + epsilon)\n",
    "\n",
    "    return 1 - dice_ratio\n",
    "\n",
    "\n",
    "def compute_batch_loss(model, batch_ndx, batch_sample: dict, batch_size, metrics, classification_threshold=0.5):\n",
    "    img, target = batch_sample['img'], batch_sample['target']\n",
    "\n",
    "    img = img.to(device=device)\n",
    "    target = target.view(img.shape)\n",
    "    target = target.to(device=device)\n",
    "\n",
    "    prediction = model(img)    # N x 1 x H x W\n",
    "\n",
    "    dice_loss = calculate_dice_loss(prediction, target)\n",
    "\n",
    "    # Metricsに指標を保存する。\n",
    "\n",
    "    start_ndx = batch_ndx * batch_size\n",
    "    end_ndx = start_ndx + img.size(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        prediction_bool = (prediction[:, 0:1] > classification_threshold).to(torch.float32)\n",
    "\n",
    "        target = target.to(torch.uint8)\n",
    "\n",
    "        dice_coefficient = 1 - calculate_dice_loss(prediction_bool, target)\n",
    "        true_positive = (prediction_bool * target).sum(dim=[1, 2, 3])\n",
    "        false_negative = ((1 - prediction_bool) * target).sum(dim=[1, 2, 3])\n",
    "        false_positive = (prediction_bool * (~target)).sum(dim=[1, 2, 3])\n",
    "\n",
    "        metrics[METRICS_DICE_LOSS_NDX, start_ndx:end_ndx] = dice_loss\n",
    "        metrics[METRICS_DICE_COEFFICIENT_NDX, start_ndx:end_ndx] = dice_coefficient\n",
    "        metrics[METRICS_TP_NDX, start_ndx:end_ndx] = true_positive\n",
    "        metrics[METRICS_FN_NDX, start_ndx:end_ndx] = false_negative\n",
    "        metrics[METRICS_FP_NDX, start_ndx:end_ndx] = false_positive\n",
    "\n",
    "    return dice_loss.mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 損失関数のDebug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:35:19.961728Z",
     "iopub.status.busy": "2023-02-14T08:35:19.961240Z",
     "iopub.status.idle": "2023-02-14T08:35:20.387315Z",
     "shell.execute_reply": "2023-02-14T08:35:20.386117Z",
     "shell.execute_reply.started": "2023-02-14T08:35:19.961686Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 06:34:52,624 INFO     pid:17999 __main__:028:__init__ <__main__.UltrasoundNerveDataset object at 0x7f018d2098e0>: 6 validation samples\n",
      "2023-02-16 06:34:52,723 DEBUG    pid:17999 __main__:008:<cell line: 2> torch.Size([6, 1, 448, 608])\n"
     ]
    }
   ],
   "source": [
    "debug_loss_loader= DataLoader(dataset=UltrasoundNerveDataset(is_val=True, val_stride=1000, only_nerve_imgs=False, transform=TRANSFORM), batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "for sample in debug_loss_loader:\n",
    "    target = sample['target']\n",
    "    if RESIZE:\n",
    "        target = target.view(6, 1, 448, 608)\n",
    "    else:\n",
    "        target = target.view(6, 1, 420, 580)\n",
    "    log.debug(target.shape)\n",
    "    losses = calculate_dice_loss(target, target)\n",
    "    assert losses.max().item() == 0.0\n",
    "    assert losses.min().item() == 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:35:25.548081Z",
     "iopub.status.busy": "2023-02-14T08:35:25.547066Z",
     "iopub.status.idle": "2023-02-14T08:35:25.554678Z",
     "shell.execute_reply": "2023-02-14T08:35:25.553561Z",
     "shell.execute_reply.started": "2023-02-14T08:35:25.548044Z"
    }
   },
   "outputs": [],
   "source": [
    "class ModelForDebug(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 64, 3, padding=\"same\", padding_mode=\"zeros\")\n",
    "        self.conv2 = nn.Conv2d(64, 1, 3, padding=\"same\", padding_mode=\"zeros\")\n",
    "        self.batch_norm = nn.BatchNorm2d(64)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.batch_norm(self.conv1(x))\n",
    "        out = torch.sigmoid(self.conv2(out))\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### UNet with Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:35:23.562637Z",
     "iopub.status.busy": "2023-02-14T08:35:23.562271Z",
     "iopub.status.idle": "2023-02-14T08:35:23.582086Z",
     "shell.execute_reply": "2023-02-14T08:35:23.580865Z",
     "shell.execute_reply.started": "2023-02-14T08:35:23.562605Z"
    }
   },
   "outputs": [],
   "source": [
    "class UNetBatchNormConvBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, kernel_size=3, activation=torch.relu):\n",
    "        super(UNetBatchNormConvBlock, self).__init__()\n",
    "        self.batch_norm = nn.BatchNorm2d(out_size)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_size)\n",
    "        self.conv = nn.Conv2d(in_size, out_size, kernel_size)\n",
    "        self.conv2 = nn.Conv2d(out_size, out_size, kernel_size)\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.activation(self.batch_norm(self.conv(x)))\n",
    "        out = self.activation(self.batch_norm2(self.conv2(out)))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetBatchNormUpBlock(nn.Module):\n",
    "    def __init__(self, in_size, out_size, kernel_size=3, activation=torch.relu, space_dropout=False):\n",
    "        super(UNetBatchNormUpBlock, self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_size, out_size, 2, stride=2)\n",
    "        self.conv = nn.Conv2d(in_size, out_size, kernel_size)\n",
    "        self.conv2 = nn.Conv2d(out_size, out_size, kernel_size)\n",
    "        self.batch_norm = nn.BatchNorm2d(out_size)\n",
    "        self.batch_norm2 = nn.BatchNorm2d(out_size)\n",
    "        self.activation = activation\n",
    "\n",
    "    def center_crop(self, layer: torch.Tensor, target_height, target_width):\n",
    "        batch_size, n_channels, layer_height, layer_width = layer.size()\n",
    "        height_remove = (layer_height - target_height) // 2\n",
    "        width_remove = (layer_width - target_width) // 2\n",
    "        return layer[:, :, height_remove:(height_remove + target_height), width_remove:(width_remove + target_width)]\n",
    "\n",
    "    def forward(self, x, bridge):\n",
    "        up = self.up(x)\n",
    "        crop1 = self.center_crop(bridge, up.size()[2], up.size()[3])\n",
    "        out = torch.cat([up, crop1], 1)\n",
    "        out = self.activation(self.batch_norm(self.conv(out)))\n",
    "        out = self.activation(self.batch_norm2(self.conv2(out)))\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class UNetBatchNorm(nn.Module):\n",
    "    def __init__(self, imsize):\n",
    "        super(UNetBatchNorm, self).__init__()\n",
    "        self.imsize = imsize\n",
    "\n",
    "        self.activation = torch.relu\n",
    "\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.conv_block1_64 = UNetBatchNormConvBlock(1, 64)\n",
    "        self.conv_block64_128 = UNetBatchNormConvBlock(64, 128)\n",
    "        self.conv_block128_256 = UNetBatchNormConvBlock(128, 256)\n",
    "        self.conv_block256_512 = UNetBatchNormConvBlock(256, 512)\n",
    "\n",
    "        self.up_block512_256 = UNetBatchNormUpBlock(512, 256)\n",
    "        self.up_block256_128 = UNetBatchNormUpBlock(256, 128)\n",
    "        self.up_block128_64 = UNetBatchNormUpBlock(128, 64)\n",
    "\n",
    "        self.last = nn.Conv2d(64, 1, 1)\n",
    "        self.pad = nn.ConstantPad2d(44, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        block1 = self.conv_block1_64(x)\n",
    "        pool1 = self.pool1(block1)\n",
    "\n",
    "        block2 = self.conv_block64_128(pool1)\n",
    "        pool2 = self.pool2(block2)\n",
    "\n",
    "        block3 = self.conv_block128_256(pool2)\n",
    "        pool3 = self.pool3(block3)\n",
    "\n",
    "        block4 = self.conv_block256_512(pool3)\n",
    "\n",
    "        up1 = self.up_block512_256(block4, block3)\n",
    "\n",
    "        up2 = self.up_block256_128(up1, block2)\n",
    "\n",
    "        up3 = self.up_block128_64(up2, block1)\n",
    "\n",
    "        return self.pad(torch.sigmoid(self.last(up3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Segmentation Models Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:35:24.246582Z",
     "iopub.status.busy": "2023-02-14T08:35:24.246014Z",
     "iopub.status.idle": "2023-02-14T08:35:24.266010Z",
     "shell.execute_reply": "2023-02-14T08:35:24.265030Z",
     "shell.execute_reply.started": "2023-02-14T08:35:24.246538Z"
    }
   },
   "outputs": [],
   "source": [
    "def unet_plus_plus():\n",
    "    model = smp.UnetPlusPlus(\n",
    "    encoder_name=\"resnet34\",\n",
    "    encoder_weights=\"imagenet\",\n",
    "    in_channels=1,\n",
    "    classes=1,\n",
    "    )\n",
    "    return model\n",
    "\n",
    "def ma_net():\n",
    "    model = smp.MAnet(in_channels=1, classes=1, activation=\"sigmoid\")\n",
    "    return model\n",
    "\n",
    "def deep_lab_v3_plus(encoder_weights=\"imagenet\"):\n",
    "    model = smp.DeepLabV3Plus(encoder_weights=encoder_weights, in_channels=1, classes=1, activation=\"sigmoid\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを選択する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:35:27.214779Z",
     "iopub.status.busy": "2023-02-14T08:35:27.213947Z",
     "iopub.status.idle": "2023-02-14T08:35:54.709427Z",
     "shell.execute_reply": "2023-02-14T08:35:54.708244Z",
     "shell.execute_reply.started": "2023-02-14T08:35:27.214739Z"
    }
   },
   "outputs": [],
   "source": [
    "def select_model(model_str: str):\n",
    "    model = None\n",
    "    model_str = model_str.lower()\n",
    "    if model_str == \"debug\":\n",
    "        model = ModelForDebug()\n",
    "    elif model_str == \"init\":\n",
    "        model =  InitNeuralNetwork()\n",
    "    elif model_str == 'unet':\n",
    "        model =  UNet(imsize=420*580)\n",
    "    elif model_str == 'unet_pad':\n",
    "        model = UNetPadEach(imsize=420*580)\n",
    "    elif model_str == 'unet_bn':\n",
    "        model = UNetBatchNorm(imsize=420*580)\n",
    "    elif model_str == 'unet_with_library':\n",
    "        model = unet_plus_plus()\n",
    "    elif model_str == 'manet':\n",
    "        model = ma_net()\n",
    "    elif model_str == 'deep_lab_v3_plus':\n",
    "        model = deep_lab_v3_plus(None)\n",
    "\n",
    "\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        model = nn.DataParallel(model)\n",
    "    model = model.to(device=device)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = select_model(model_str=MODEL_STR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルを確認する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "====================================================================================================\n",
       "Layer (type:depth-idx)                             Output Shape              Param #\n",
       "====================================================================================================\n",
       "MAnet                                              [8, 1, 448, 608]          --\n",
       "├─ResNetEncoder: 1-1                               [8, 1, 448, 608]          --\n",
       "│    └─Conv2d: 2-1                                 [8, 64, 224, 304]         3,136\n",
       "│    └─BatchNorm2d: 2-2                            [8, 64, 224, 304]         128\n",
       "│    └─ReLU: 2-3                                   [8, 64, 224, 304]         --\n",
       "│    └─MaxPool2d: 2-4                              [8, 64, 112, 152]         --\n",
       "│    └─Sequential: 2-5                             [8, 64, 112, 152]         --\n",
       "│    │    └─BasicBlock: 3-1                        [8, 64, 112, 152]         73,984\n",
       "│    │    └─BasicBlock: 3-2                        [8, 64, 112, 152]         73,984\n",
       "│    │    └─BasicBlock: 3-3                        [8, 64, 112, 152]         73,984\n",
       "│    └─Sequential: 2-6                             [8, 128, 56, 76]          --\n",
       "│    │    └─BasicBlock: 3-4                        [8, 128, 56, 76]          230,144\n",
       "│    │    └─BasicBlock: 3-5                        [8, 128, 56, 76]          295,424\n",
       "│    │    └─BasicBlock: 3-6                        [8, 128, 56, 76]          295,424\n",
       "│    │    └─BasicBlock: 3-7                        [8, 128, 56, 76]          295,424\n",
       "│    └─Sequential: 2-7                             [8, 256, 28, 38]          --\n",
       "│    │    └─BasicBlock: 3-8                        [8, 256, 28, 38]          919,040\n",
       "│    │    └─BasicBlock: 3-9                        [8, 256, 28, 38]          1,180,672\n",
       "│    │    └─BasicBlock: 3-10                       [8, 256, 28, 38]          1,180,672\n",
       "│    │    └─BasicBlock: 3-11                       [8, 256, 28, 38]          1,180,672\n",
       "│    │    └─BasicBlock: 3-12                       [8, 256, 28, 38]          1,180,672\n",
       "│    │    └─BasicBlock: 3-13                       [8, 256, 28, 38]          1,180,672\n",
       "│    └─Sequential: 2-8                             [8, 512, 14, 19]          --\n",
       "│    │    └─BasicBlock: 3-14                       [8, 512, 14, 19]          3,673,088\n",
       "│    │    └─BasicBlock: 3-15                       [8, 512, 14, 19]          4,720,640\n",
       "│    │    └─BasicBlock: 3-16                       [8, 512, 14, 19]          4,720,640\n",
       "├─MAnetDecoder: 1-2                                [8, 16, 448, 608]         --\n",
       "│    └─PAB: 2-9                                    [8, 512, 14, 19]          --\n",
       "│    │    └─Conv2d: 3-17                           [8, 64, 14, 19]           32,832\n",
       "│    │    └─Conv2d: 3-18                           [8, 64, 14, 19]           32,832\n",
       "│    │    └─Conv2d: 3-19                           [8, 512, 14, 19]          2,359,808\n",
       "│    │    └─Softmax: 3-20                          [8, 70756]                --\n",
       "│    │    └─Conv2d: 3-21                           [8, 512, 14, 19]          2,359,808\n",
       "│    └─ModuleList: 2-10                            --                        --\n",
       "│    │    └─MFAB: 3-22                             [8, 256, 28, 38]          4,279,328\n",
       "│    │    └─MFAB: 3-23                             [8, 128, 56, 76]          1,070,608\n",
       "│    │    └─MFAB: 3-24                             [8, 64, 112, 152]         268,040\n",
       "│    │    └─MFAB: 3-25                             [8, 32, 224, 304]         88,584\n",
       "│    │    └─DecoderBlock: 3-26                     [8, 16, 448, 608]         6,976\n",
       "├─SegmentationHead: 1-3                            [8, 1, 448, 608]          --\n",
       "│    └─Conv2d: 2-11                                [8, 1, 448, 608]          145\n",
       "│    └─Identity: 2-12                              [8, 1, 448, 608]          --\n",
       "│    └─Activation: 2-13                            [8, 1, 448, 608]          --\n",
       "│    │    └─Sigmoid: 3-27                          [8, 1, 448, 608]          --\n",
       "====================================================================================================\n",
       "Total params: 31,777,361\n",
       "Trainable params: 31,777,361\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (G): 273.00\n",
       "====================================================================================================\n",
       "Input size (MB): 8.72\n",
       "Forward/backward pass size (MB): 5258.17\n",
       "Params size (MB): 127.11\n",
       "Estimated Total Size (MB): 5394.00\n",
       "===================================================================================================="
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model=model, input_size=(BATCH_SIZE, 1, 448, 608))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:36:28.457026Z",
     "iopub.status.busy": "2023-02-14T08:36:28.456642Z",
     "iopub.status.idle": "2023-02-14T08:36:32.846820Z",
     "shell.execute_reply": "2023-02-14T08:36:32.845707Z",
     "shell.execute_reply.started": "2023-02-14T08:36:28.456986Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 06:35:03,160 INFO     pid:17999 __main__:028:__init__ <__main__.UltrasoundNerveDataset object at 0x7f0184a8ad30>: 3756 training samples\n",
      "2023-02-16 06:35:03,207 INFO     pid:17999 __main__:028:__init__ <__main__.UltrasoundNerveDataset object at 0x7f0184a8acd0>: 1879 validation samples\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "train_loader= init_dataloader(is_val=False, only_nerve_imgs=False, transform=TRANSFORM)\n",
    "val_loader = init_dataloader(is_val=True, only_nerve_imgs=False, transform=TRANSFORM)\n",
    "train_writer, val_writer = init_tensor_board_writers()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:57:57.540322Z",
     "iopub.status.busy": "2023-02-14T08:57:57.539878Z",
     "iopub.status.idle": "2023-02-14T08:57:57.567704Z",
     "shell.execute_reply": "2023-02-14T08:57:57.566545Z",
     "shell.execute_reply.started": "2023-02-14T08:57:57.540265Z"
    }
   },
   "outputs": [],
   "source": [
    "def do_train(model, epoch_ndx, train_dataloader, total_training_samples_count):\n",
    "    torch.autograd.set_detect_anomaly(True)\n",
    "    model.train()\n",
    "    # 指標の入力\n",
    "    train_metrics = torch.zeros(METRICS_SIZE, len(train_dataloader.dataset), device=device)\n",
    "\n",
    "#     batch_iter = enumerateWithEstimate(train_dataloader, \"E{} Training\".format(epoch_ndx), start_ndx=train_dataloader.num_workers)\n",
    "\n",
    "    with tqdm(train_dataloader) as pbar:\n",
    "\n",
    "        for batch_ndx, batch_samples in enumerate(pbar):\n",
    "\n",
    "            batch_loss = compute_batch_loss(model, batch_ndx, batch_samples, train_dataloader.batch_size, train_metrics)\n",
    "            pbar.set_description(\"Training #{}\".format(epoch_ndx))\n",
    "            pbar.set_postfix(loss=batch_loss.item())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        total_training_samples_count += train_metrics.size(1)\n",
    "\n",
    "        return train_metrics.cpu(), total_training_samples_count\n",
    "\n",
    "def do_validation(model, epoch_ndx, val_dataloader):\n",
    "    with torch.inference_mode():\n",
    "        model.eval()\n",
    "        val_metrics = torch.zeros(METRICS_SIZE, len(val_dataloader.dataset), device=device)\n",
    "\n",
    "        with tqdm(val_dataloader) as pbar_val:\n",
    "            for batch_ndx, batch_samples in enumerate(pbar_val):\n",
    "                pbar_val.set_description(\"Validation #{}\".format(epoch_ndx))\n",
    "                compute_batch_loss(model, batch_ndx, batch_samples, val_dataloader.batch_size, val_metrics)\n",
    "\n",
    "    return val_metrics.cpu()\n",
    "\n",
    "\n",
    "def log_metrics(epoch_ndx, mode_str, metrics, tensorboard_writer, total_training_samples_count):\n",
    "\n",
    "    metrics_numpy = metrics.detach().numpy()\n",
    "    sum_metrics = metrics_numpy.sum(axis=1)\n",
    "    assert np.isfinite(metrics).all()\n",
    "\n",
    "    all_positive_count = sum_metrics[METRICS_TP_NDX] + sum_metrics[METRICS_FN_NDX]\n",
    "\n",
    "    metrics_dict = {}\n",
    "    metrics_dict['dice_loss'] = metrics_numpy[METRICS_DICE_LOSS_NDX].mean()\n",
    "    metrics_dict['dice_coefficient'] = metrics_numpy[METRICS_DICE_COEFFICIENT_NDX].mean()\n",
    "    metrics_dict['percent_all/true_positive'] = sum_metrics[METRICS_TP_NDX] / (all_positive_count or 1) * 100\n",
    "    metrics_dict['percent_all/false_negative'] = sum_metrics[METRICS_FN_NDX] / (all_positive_count or 1) * 100\n",
    "    metrics_dict['percent_all/false_positive'] = sum_metrics[METRICS_FP_NDX] / (all_positive_count or 1) * 100\n",
    "\n",
    "    precision = metrics_dict['pr/precision'] = sum_metrics[METRICS_TP_NDX] / ((sum_metrics[METRICS_TP_NDX] + sum_metrics[METRICS_FP_NDX]) or 1)\n",
    "    recall = metrics_dict['pr/recall'] = sum_metrics[METRICS_TP_NDX] / ((sum_metrics[METRICS_TP_NDX] + sum_metrics[METRICS_FN_NDX]) or 1)\n",
    "\n",
    "    metrics_dict['pr/f1_score'] = 2 * (precision * recall) / ((precision + recall) or 1)\n",
    "\n",
    "    log.info((\"E{} {:8} \"\n",
    "              + \"Dice loss: {dice_loss:.4f}, \").format(\n",
    "        epoch_ndx, mode_str, **metrics_dict\n",
    "    ))\n",
    "\n",
    "    log.info((\"E{} {:8} \"\n",
    "              + \"Dice coefficient: {dice_coefficient:.4f}, \").format(\n",
    "        epoch_ndx, mode_str, **metrics_dict\n",
    "    ))\n",
    "    \n",
    "    for key, value in metrics_dict.items():\n",
    "        tensorboard_writer.add_scalar(key, value, total_training_samples_count, new_style=True)\n",
    "        tensorboard_writer.flush()\n",
    "            \n",
    "    score = metrics_dict['dice_coefficient']\n",
    "\n",
    "    return score\n",
    "\n",
    "def log_images(model, mode_str, dataloader, tensorboard_writer, epochs, total_training_samples_count):\n",
    "    model.eval()\n",
    "\n",
    "    sample_batch = next(iter(dataloader))\n",
    "    imgs_model, targets = sample_batch['img'], sample_batch['target']\n",
    "\n",
    "\n",
    "    # visualize image\n",
    "    imgs_vis = sample_batch['img_vis']\n",
    "\n",
    "    # target mask\n",
    "    targets_masks = targets.to(torch.bool)\n",
    "\n",
    "    # model\n",
    "    imgs_g = imgs_model.to(device=device)\n",
    "    outputs = model(imgs_g)\n",
    "    targets_for_loss = targets.unsqueeze(1).to(device=device)\n",
    "    loss = calculate_dice_loss(outputs, targets_for_loss)\n",
    "\n",
    "    # output mask\n",
    "    outputs_masks = outputs >= 0.5\n",
    "    outputs_masks = torch.squeeze(outputs_masks, 1)\n",
    "    outputs.cpu()\n",
    "\n",
    "    # input image\n",
    "    rg = torch.zeros(imgs_vis.shape[0:1] +  (2,) + imgs_vis.shape[2:4], dtype=torch.uint8)\n",
    "    imgs_rgb = torch.cat((rg, imgs_vis), 1).to(dtype=torch.uint8)\n",
    "\n",
    "    # mask\n",
    "    outputs_with_masks = [draw_segmentation_masks(img_rgb, masks=output, alpha=.3, colors=\"#FFFFFF\") for img_rgb, output in zip(imgs_rgb, outputs_masks)]\n",
    "    targets_with_masks = [draw_segmentation_masks(img_rgb, masks=target, alpha=.3, colors=\"#FFFFFF\") for img_rgb, target in zip(imgs_rgb, targets_masks)]\n",
    "\n",
    "    for image_ndx, (output_mask, target_mask) in enumerate(zip(outputs_with_masks, targets_with_masks)):\n",
    "\n",
    "        tensorboard_writer.add_image(f'{mode_str}/E{epochs}_#{image_ndx}_prediction_{loss[image_ndx].item():.3f}loss', output_mask, total_training_samples_count, dataformats='CHW')\n",
    "        tensorboard_writer.add_image(f'{mode_str}/E{epochs}_#{image_ndx}_label', target_mask, total_training_samples_count, dataformats='CHW')\n",
    "        tensorboard_writer.flush()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 実行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard利用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:58:00.187753Z",
     "iopub.status.busy": "2023-02-14T08:58:00.186894Z",
     "iopub.status.idle": "2023-02-14T08:58:00.192603Z",
     "shell.execute_reply": "2023-02-14T08:58:00.191380Z",
     "shell.execute_reply.started": "2023-02-14T08:58:00.187714Z"
    }
   },
   "outputs": [],
   "source": [
    "# model_name = type(model).__name__\n",
    "# base_dir = os.path.dirname(os.path.abspath('.'))\n",
    "# time_str = datetime.datetime.now().strftime('%Y_%m_%d_%H.%M.%S')\n",
    "# log_dir = os.path.join(base_dir, 'working', 'log', '{model}_{epochs}epochs_{batch_size}batches'.format(model=model_name, epochs=EPOCHS, batch_size=BATCH_SIZE), time_str)\n",
    "\n",
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-02-14T08:58:00.401694Z",
     "iopub.status.busy": "2023-02-14T08:58:00.401306Z",
     "iopub.status.idle": "2023-02-14T08:58:48.800736Z",
     "shell.execute_reply": "2023-02-14T08:58:48.798833Z",
     "shell.execute_reply.started": "2023-02-14T08:58:00.401662Z"
    },
    "pycharm": {
     "is_executing": true
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-02-16 06:35:03,243 INFO     pid:17999 __main__:001:<cell line: 1> Starting MAnet\n",
      "2023-02-16 06:35:03,245 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 1 of 30, 470/235 batches of size 8*1\n",
      "Training #1: 100%|██████████| 470/470 [04:04<00:00,  1.92it/s, loss=0.251]  \n",
      "2023-02-16 06:39:07,957 INFO     pid:17999 __main__:060:log_metrics E1 Training Dice loss: 0.7241, \n",
      "2023-02-16 06:39:07,958 INFO     pid:17999 __main__:065:log_metrics E1 Training Dice coefficient: 0.3147, \n",
      "Validation #1: 100%|██████████| 235/235 [00:33<00:00,  7.07it/s]\n",
      "2023-02-16 06:39:41,254 INFO     pid:17999 __main__:060:log_metrics E1 Validation Dice loss: 0.4204, \n",
      "2023-02-16 06:39:41,255 INFO     pid:17999 __main__:065:log_metrics E1 Validation Dice coefficient: 0.5823, \n",
      "2023-02-16 06:39:46,041 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 2 of 30, 470/235 batches of size 8*1\n",
      "Training #2: 100%|██████████| 470/470 [04:16<00:00,  1.83it/s, loss=0.5]     \n",
      "2023-02-16 06:44:02,300 INFO     pid:17999 __main__:060:log_metrics E2 Training Dice loss: 0.4097, \n",
      "2023-02-16 06:44:02,301 INFO     pid:17999 __main__:065:log_metrics E2 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 06:44:02,304 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 3 of 30, 470/235 batches of size 8*1\n",
      "Training #3: 100%|██████████| 470/470 [04:25<00:00,  1.77it/s, loss=0.5]     \n",
      "2023-02-16 06:48:27,542 INFO     pid:17999 __main__:060:log_metrics E3 Training Dice loss: 0.4095, \n",
      "2023-02-16 06:48:27,543 INFO     pid:17999 __main__:065:log_metrics E3 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 06:48:27,546 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 4 of 30, 470/235 batches of size 8*1\n",
      "Training #4: 100%|██████████| 470/470 [04:26<00:00,  1.77it/s, loss=0.25]   \n",
      "2023-02-16 06:52:53,788 INFO     pid:17999 __main__:060:log_metrics E4 Training Dice loss: 0.4095, \n",
      "2023-02-16 06:52:53,788 INFO     pid:17999 __main__:065:log_metrics E4 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 06:52:53,791 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 5 of 30, 470/235 batches of size 8*1\n",
      "Training #5: 100%|██████████| 470/470 [04:25<00:00,  1.77it/s, loss=3.68e-5]\n",
      "2023-02-16 06:57:19,469 INFO     pid:17999 __main__:060:log_metrics E5 Training Dice loss: 0.4094, \n",
      "2023-02-16 06:57:19,470 INFO     pid:17999 __main__:065:log_metrics E5 Training Dice coefficient: 0.5906, \n",
      "Validation #5: 100%|██████████| 235/235 [00:36<00:00,  6.42it/s]\n",
      "2023-02-16 06:57:56,149 INFO     pid:17999 __main__:060:log_metrics E5 Validation Dice loss: 0.4177, \n",
      "2023-02-16 06:57:56,149 INFO     pid:17999 __main__:065:log_metrics E5 Validation Dice coefficient: 0.5823, \n",
      "2023-02-16 06:58:00,941 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 6 of 30, 470/235 batches of size 8*1\n",
      "Training #6: 100%|██████████| 470/470 [04:25<00:00,  1.77it/s, loss=1]      \n",
      "2023-02-16 07:02:26,702 INFO     pid:17999 __main__:060:log_metrics E6 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:02:26,702 INFO     pid:17999 __main__:065:log_metrics E6 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:02:26,705 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 7 of 30, 470/235 batches of size 8*1\n",
      "Training #7: 100%|██████████| 470/470 [04:24<00:00,  1.78it/s, loss=1]      \n",
      "2023-02-16 07:06:51,217 INFO     pid:17999 __main__:060:log_metrics E7 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:06:51,218 INFO     pid:17999 __main__:065:log_metrics E7 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:06:51,221 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 8 of 30, 470/235 batches of size 8*1\n",
      "Training #8: 100%|██████████| 470/470 [04:24<00:00,  1.78it/s, loss=0.25]   \n",
      "2023-02-16 07:11:15,865 INFO     pid:17999 __main__:060:log_metrics E8 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:11:15,866 INFO     pid:17999 __main__:065:log_metrics E8 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:11:15,869 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 9 of 30, 470/235 batches of size 8*1\n",
      "Training #9: 100%|██████████| 470/470 [04:11<00:00,  1.87it/s, loss=0.5]    \n",
      "2023-02-16 07:15:27,558 INFO     pid:17999 __main__:060:log_metrics E9 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:15:27,559 INFO     pid:17999 __main__:065:log_metrics E9 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:15:27,562 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 10 of 30, 470/235 batches of size 8*1\n",
      "Training #10: 100%|██████████| 470/470 [04:09<00:00,  1.88it/s, loss=0.75]   \n",
      "2023-02-16 07:19:37,218 INFO     pid:17999 __main__:060:log_metrics E10 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:19:37,219 INFO     pid:17999 __main__:065:log_metrics E10 Training Dice coefficient: 0.5906, \n",
      "Validation #10: 100%|██████████| 235/235 [00:32<00:00,  7.14it/s]\n",
      "2023-02-16 07:20:10,184 INFO     pid:17999 __main__:060:log_metrics E10 Validation Dice loss: 0.4177, \n",
      "2023-02-16 07:20:10,185 INFO     pid:17999 __main__:065:log_metrics E10 Validation Dice coefficient: 0.5823, \n",
      "2023-02-16 07:20:15,045 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 11 of 30, 470/235 batches of size 8*1\n",
      "Training #11: 100%|██████████| 470/470 [04:11<00:00,  1.87it/s, loss=1]      \n",
      "2023-02-16 07:24:26,092 INFO     pid:17999 __main__:060:log_metrics E11 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:24:26,093 INFO     pid:17999 __main__:065:log_metrics E11 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:24:26,096 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 12 of 30, 470/235 batches of size 8*1\n",
      "Training #12: 100%|██████████| 470/470 [04:24<00:00,  1.77it/s, loss=0.25]   \n",
      "2023-02-16 07:28:51,047 INFO     pid:17999 __main__:060:log_metrics E12 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:28:51,048 INFO     pid:17999 __main__:065:log_metrics E12 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:28:51,051 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 13 of 30, 470/235 batches of size 8*1\n",
      "Training #13: 100%|██████████| 470/470 [04:26<00:00,  1.76it/s, loss=1]      \n",
      "2023-02-16 07:33:17,527 INFO     pid:17999 __main__:060:log_metrics E13 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:33:17,528 INFO     pid:17999 __main__:065:log_metrics E13 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:33:17,531 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 14 of 30, 470/235 batches of size 8*1\n",
      "Training #14: 100%|██████████| 470/470 [04:14<00:00,  1.84it/s, loss=0.25]   \n",
      "2023-02-16 07:37:32,295 INFO     pid:17999 __main__:060:log_metrics E14 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:37:32,295 INFO     pid:17999 __main__:065:log_metrics E14 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:37:32,298 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 15 of 30, 470/235 batches of size 8*1\n",
      "Training #15: 100%|██████████| 470/470 [04:07<00:00,  1.90it/s, loss=0.75]   \n",
      "2023-02-16 07:41:40,288 INFO     pid:17999 __main__:060:log_metrics E15 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:41:40,289 INFO     pid:17999 __main__:065:log_metrics E15 Training Dice coefficient: 0.5906, \n",
      "Validation #15: 100%|██████████| 235/235 [00:35<00:00,  6.66it/s]\n",
      "2023-02-16 07:42:15,675 INFO     pid:17999 __main__:060:log_metrics E15 Validation Dice loss: 0.4177, \n",
      "2023-02-16 07:42:15,676 INFO     pid:17999 __main__:065:log_metrics E15 Validation Dice coefficient: 0.5823, \n",
      "2023-02-16 07:42:20,496 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 16 of 30, 470/235 batches of size 8*1\n",
      "Training #16: 100%|██████████| 470/470 [04:24<00:00,  1.78it/s, loss=0.25]   \n",
      "2023-02-16 07:46:45,185 INFO     pid:17999 __main__:060:log_metrics E16 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:46:45,185 INFO     pid:17999 __main__:065:log_metrics E16 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:46:45,188 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 17 of 30, 470/235 batches of size 8*1\n",
      "Training #17: 100%|██████████| 470/470 [04:24<00:00,  1.78it/s, loss=0.5]    \n",
      "2023-02-16 07:51:09,541 INFO     pid:17999 __main__:060:log_metrics E17 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:51:09,542 INFO     pid:17999 __main__:065:log_metrics E17 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:51:09,545 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 18 of 30, 470/235 batches of size 8*1\n",
      "Training #18: 100%|██████████| 470/470 [04:24<00:00,  1.77it/s, loss=0.75]   \n",
      "2023-02-16 07:55:34,439 INFO     pid:17999 __main__:060:log_metrics E18 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:55:34,439 INFO     pid:17999 __main__:065:log_metrics E18 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:55:34,443 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 19 of 30, 470/235 batches of size 8*1\n",
      "Training #19: 100%|██████████| 470/470 [04:24<00:00,  1.77it/s, loss=0.5]    \n",
      "2023-02-16 07:59:59,445 INFO     pid:17999 __main__:060:log_metrics E19 Training Dice loss: 0.4094, \n",
      "2023-02-16 07:59:59,446 INFO     pid:17999 __main__:065:log_metrics E19 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 07:59:59,449 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 20 of 30, 470/235 batches of size 8*1\n",
      "Training #20: 100%|██████████| 470/470 [04:24<00:00,  1.78it/s, loss=0.5]    \n",
      "2023-02-16 08:04:24,100 INFO     pid:17999 __main__:060:log_metrics E20 Training Dice loss: 0.4094, \n",
      "2023-02-16 08:04:24,101 INFO     pid:17999 __main__:065:log_metrics E20 Training Dice coefficient: 0.5906, \n",
      "Validation #20: 100%|██████████| 235/235 [00:36<00:00,  6.45it/s]\n",
      "2023-02-16 08:05:00,608 INFO     pid:17999 __main__:060:log_metrics E20 Validation Dice loss: 0.4177, \n",
      "2023-02-16 08:05:00,608 INFO     pid:17999 __main__:065:log_metrics E20 Validation Dice coefficient: 0.5823, \n",
      "2023-02-16 08:05:05,367 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 21 of 30, 470/235 batches of size 8*1\n",
      "Training #21: 100%|██████████| 470/470 [04:25<00:00,  1.77it/s, loss=0.25]   \n",
      "2023-02-16 08:09:31,039 INFO     pid:17999 __main__:060:log_metrics E21 Training Dice loss: 0.4094, \n",
      "2023-02-16 08:09:31,039 INFO     pid:17999 __main__:065:log_metrics E21 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 08:09:31,042 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 22 of 30, 470/235 batches of size 8*1\n",
      "Training #22: 100%|██████████| 470/470 [04:27<00:00,  1.76it/s, loss=0.75]   \n",
      "2023-02-16 08:13:58,445 INFO     pid:17999 __main__:060:log_metrics E22 Training Dice loss: 0.4094, \n",
      "2023-02-16 08:13:58,445 INFO     pid:17999 __main__:065:log_metrics E22 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 08:13:58,448 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 23 of 30, 470/235 batches of size 8*1\n",
      "Training #23: 100%|██████████| 470/470 [04:18<00:00,  1.82it/s, loss=0.75]   \n",
      "2023-02-16 08:18:17,159 INFO     pid:17999 __main__:060:log_metrics E23 Training Dice loss: 0.4094, \n",
      "2023-02-16 08:18:17,160 INFO     pid:17999 __main__:065:log_metrics E23 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 08:18:17,163 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 24 of 30, 470/235 batches of size 8*1\n",
      "Training #24: 100%|██████████| 470/470 [04:09<00:00,  1.89it/s, loss=0.5]    \n",
      "2023-02-16 08:22:26,400 INFO     pid:17999 __main__:060:log_metrics E24 Training Dice loss: 0.4094, \n",
      "2023-02-16 08:22:26,400 INFO     pid:17999 __main__:065:log_metrics E24 Training Dice coefficient: 0.5906, \n",
      "2023-02-16 08:22:26,403 INFO     pid:17999 __main__:009:<cell line: 7> Epoch 25 of 30, 470/235 batches of size 8*1\n",
      "Training #25:  73%|███████▎  | 345/470 [03:13<01:10,  1.76it/s, loss=0.375]  "
     ]
    }
   ],
   "source": [
    "log.info(\"Starting {}\".format(type(model).__name__))\n",
    "\n",
    "best_score = 0.0\n",
    "validation_cadence = 5\n",
    "epochs = EPOCHS\n",
    "total_training_samples_count = 0\n",
    "for epoch_ndx in (range(1, epochs + 1)):\n",
    "\n",
    "    log.info(\"Epoch {} of {}, {}/{} batches of size {}*{}\".format(\n",
    "        epoch_ndx,\n",
    "        epochs,\n",
    "        len(train_loader),\n",
    "        len(val_loader),\n",
    "        BATCH_SIZE,\n",
    "        (torch.cuda.device_count() if torch.cuda.is_available() else 1),\n",
    "    ))\n",
    "\n",
    "    train_metrics, total_training_samples_count = do_train(model, epoch_ndx, train_loader, total_training_samples_count)\n",
    "    log_metrics(epoch_ndx, 'Training', train_metrics, train_writer, total_training_samples_count)\n",
    "\n",
    "    if epoch_ndx == 1 or epoch_ndx % validation_cadence == 0 or epoch_ndx == epochs:\n",
    "        val_metrics = do_validation(model, epoch_ndx, val_loader)\n",
    "        # Score is calculated with Dice Coefficient.\n",
    "        score = log_metrics(epoch_ndx, 'Validation', val_metrics, val_writer, total_training_samples_count)\n",
    "        best_score = max(score, best_score)\n",
    "        \n",
    "        log_images(model, 'Training', train_loader, train_writer, epoch_ndx, total_training_samples_count)\n",
    "        log_images(model, 'Validation', val_loader, val_writer, epoch_ndx, total_training_samples_count)\n",
    "\n",
    "log.info('Best Score: {}'.format(best_score))\n",
    "train_writer.close()\n",
    "val_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "base_dir = os.path.dirname(os.path.abspath('.'))\n",
    "model_path = os.path.join(base_dir, 'models')\n",
    "if not os.path.exists(model_path):\n",
    "    os.mkdir(model_path)\n",
    "model_name = type(model).__name__\n",
    "torch.save(model, '{}/{}.pth'.format(model_path, model_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 訓練結果の出力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Visualize:\n",
    "    def __init__(self, mean: list, std: list):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "        self.pad = nn.ConstantPad2d(14, 0)\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        img, target = sample['img'], sample['target']\n",
    "        img_for_model = F.to_tensor(img)\n",
    "        img_vis = F.pil_to_tensor(img)\n",
    "        target = torch.as_tensor(np.array(target), dtype=torch.int64)\n",
    "        target = torch.abs(target)\n",
    "\n",
    "        img_for_model = F.normalize(img_for_model, self.mean, self.std)\n",
    "\n",
    "        if RESIZE:\n",
    "            img_for_model = self.pad(img_for_model)\n",
    "            target= self.pad(target)\n",
    "            img_vis = self.pad(img_vis)\n",
    "\n",
    "        sample = {'img': img_for_model, 'target': target, 'img_vis': img_vis}\n",
    "\n",
    "        return sample\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def show(imgs):\n",
    "    fig, axes = plt.subplots(ncols=len(imgs), squeeze=False, figsize=(30, 30))\n",
    "    for i, img in enumerate(imgs):\n",
    "        img = img.detach()\n",
    "        img = F.to_pil_image(img)\n",
    "        axes[0, i].imshow(np.asarray(img))\n",
    "        axes[0, i].set(xticklabels=[], yticklabels=[], xticks=[], yticks=[])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "def show_masks(model, classification_threshold=0.5, num_show_imgs=5):\n",
    "    val_stride = 5635 // num_show_imgs + 1\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        torch.cuda.empty_cache()\n",
    "        visualize_dataloader = DataLoader(UltrasoundNerveDataset(is_val=True, val_stride=val_stride, is_random=True, transform=Visualize(mean=[MEAN], std=[STD]), only_nerve_imgs=True), batch_size=num_show_imgs)\n",
    "        for samples in visualize_dataloader:\n",
    "            imgs_model, targets = samples['img'], samples['target']\n",
    "\n",
    "            \n",
    "            # visualize image\n",
    "            imgs_vis = samples['img_vis']\n",
    "\n",
    "            # target mask\n",
    "            targets_masks = targets.to(torch.bool)\n",
    "            \n",
    "            # model\n",
    "            imgs_g = imgs_model.to(device=device)\n",
    "            outputs = model(imgs_g)\n",
    "            \n",
    "            # output mask\n",
    "            log.info(\"Output shape: {}, Output min: {}, Output Max: {}\".format(outputs.shape, outputs.min().item(), outputs.max().item()))\n",
    "            outputs = outputs >= classification_threshold\n",
    "            outputs_masks = outputs.to(torch.bool)\n",
    "            outputs_masks = torch.squeeze(outputs_masks, 1)\n",
    "            outputs.cpu()\n",
    "            \n",
    "            # input image\n",
    "            rg = torch.zeros(imgs_vis.shape[0:1] +  (2,) + imgs_vis.shape[2:4], dtype=torch.uint8)\n",
    "            imgs_rgb = torch.cat((rg, imgs_vis), 1).to(dtype=torch.uint8)\n",
    "            \n",
    "            # mask\n",
    "            outputs_with_masks = [draw_segmentation_masks(img_rgb, masks=output, alpha=.3, colors=\"#FFFFFF\") for img_rgb, output in zip(imgs_rgb, outputs_masks)]\n",
    "            targets_with_masks = [draw_segmentation_masks(img_rgb, masks=target, alpha=0.3, colors=\"#FFFFFF\") for img_rgb, target in zip(imgs_rgb, targets_masks)]\n",
    "            show(imgs_vis)\n",
    "            show(outputs_with_masks)\n",
    "            show(targets_with_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "show_masks(model, num_show_imgs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
